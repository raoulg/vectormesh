{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from vectormesh.data.cache import VectorCache\n",
    "\n",
    "assets = Path(\"../artefacts\")\n",
    "trainpath = next(\n",
    "    assets.glob(\"aktes*/\")\n",
    ")  # change this if you dont want the first folder\n",
    "tag = trainpath.name\n",
    "cache = VectorCache.load(path=trainpath)\n",
    "train = cache.select(range(1024))\n",
    "valid = cache.select(range(1024, 2048))\n",
    "column_name = \"legal_dutch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd6326",
   "metadata": {},
   "source": [
    "We load a sample of the full dataset for this demo.\n",
    "For the exam, obviously, dont do that, and use the full 15k documents!\n",
    "\n",
    "The next piece of code will load the regexvectorizer and add it to the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh import RegexVectorizer\n",
    "from vectormesh.data.vectorizers import (\n",
    "    build_legal_reference_pattern,\n",
    "    harmonize_legal_reference,\n",
    ")\n",
    "\n",
    "# Initialize & fit with training_texts\n",
    "regexvectorizer = RegexVectorizer(\n",
    "    col_name=\"regex\",\n",
    "    pattern_builder=build_legal_reference_pattern,\n",
    "    harmonizer=harmonize_legal_reference,\n",
    "    min_doc_frequency=15,\n",
    "    max_features=200,\n",
    "    device=\"cpu\",\n",
    "    training_texts=cache[\"text\"],  # we fit it on all 15k texts!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ac2b8",
   "metadata": {},
   "source": [
    "With the regexvectorizer fitted, we can extend our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_cache = VectorCache.create(\n",
    "    cache_dir=Path(\"tmp/artefacts\"),\n",
    "    vectorizer=regexvectorizer,  # use our new regex vectorizer\n",
    "    dataset=cache.dataset,  # use the existing dataset\n",
    "    dataset_tag=tag,  # this will check for existing metadata.json\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427207e9",
   "metadata": {},
   "source": [
    "We loaded the vectorized cache from artefacts, and now we have added the onehot vectors created with the regexes. See `vectormesh.data.vectorizers` for more details.\n",
    "\n",
    "Lets have a look at a concrete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_cache[0][\"regex\"], extended_cache[0][\"regex\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700be56",
   "metadata": {},
   "source": [
    "What we will do now, is instead of feeding just one vector to the model, we want to have two vectors:\n",
    "\n",
    "- one vector is the 2D tensor from the huggingface model, shaped `(chunks, dim)`\n",
    "- the other is a 1D binary vector created with regexes. \n",
    "\n",
    "Lets call the `X1` and `X2` respectively.\n",
    "\n",
    "We now want to feed the model a tuple `(X1, X2)` as input, and the label `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1839318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class CollateParallel(BaseModel):\n",
    "    \"\"\"\n",
    "    processes a batch of Dataset items into padded tensors\n",
    "    \"\"\"\n",
    "\n",
    "    vec1_col: str\n",
    "    vec2_col: str\n",
    "    target_col: str\n",
    "    padder: Callable\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        embeddings1 = [\n",
    "            item[self.vec1_col] for item in batch\n",
    "        ]  # 2D tensors (chunks, dim)\n",
    "        embeddings2 = [item[self.vec2_col] for item in batch]  # 1D tensors (dim,)\n",
    "        X1 = self.padder(\n",
    "            embeddings1\n",
    "        )  # pad the 2D tensor, now it is a 3D (batch, chunks, dim)\n",
    "        X2 = torch.stack(embeddings2).float()  # the regex doesnt need padding\n",
    "        y = torch.stack([item[self.target_col] for item in batch]).float()\n",
    "        return (X1, X2), y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e3bd4",
   "metadata": {},
   "source": [
    "You can find this `CollaterParallel` class in `vectormesh.data.dataset`, but i show it here for clarity.\n",
    "\n",
    "Lets check all the input we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f590928",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_cache.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d603a4",
   "metadata": {},
   "source": [
    "We can now apply everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fedae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from vectormesh.components import FixedPadding\n",
    "from vectormesh.data import OneHot\n",
    "\n",
    "onehot = OneHot(num_classes=32, label_col=\"labels\", target_col=\"onehot\")\n",
    "collate_fn = CollateParallel(\n",
    "    vec1_col=\"legal_dutch\",\n",
    "    vec2_col=\"regex\",\n",
    "    target_col=\"onehot\",\n",
    "    padder=FixedPadding(max_chunks=30),\n",
    ")\n",
    "\n",
    "train = extended_cache.select(range(1024))\n",
    "valid = extended_cache.select(range(1024, 2048))\n",
    "train_oh = train.map(onehot)\n",
    "valid_oh = valid.map(onehot)\n",
    "\n",
    "trainloader = DataLoader(train_oh, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "validloader = DataLoader(valid_oh, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(trainloader))\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e53062",
   "metadata": {},
   "source": [
    "X is a tuple, exactly as we wanted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef58032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape, X[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e28fc",
   "metadata": {},
   "source": [
    "One is a 3D tensor, the other a 2D tensor.\n",
    "\n",
    "So, how can we create a model?\n",
    "\n",
    "We can use the `Parallel` pipeline, see `vectormesh.components.pipelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import (\n",
    "    Concatenate2D,\n",
    "    MeanAggregator,\n",
    "    NeuralNet,\n",
    "    Parallel,\n",
    "    Serial,\n",
    ")\n",
    "\n",
    "parallel = Parallel(\n",
    "    [\n",
    "        # (batch, chunks, dims) -> (batch, dims) -> (batch, 32)\n",
    "        Serial([MeanAggregator(), NeuralNet(hidden_size=768, out_size=32)]),\n",
    "        # (batch, dims) -> (batch, 32)\n",
    "        Serial([NeuralNet(hidden_size=123, out_size=32)]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Serial(\n",
    "    [\n",
    "        parallel,  # (X1, X2) -> (batch, 32), (batch, 32)\n",
    "        Concatenate2D(),  # (batch, 32), (batch, 32) -> (batch, 64)\n",
    "        NeuralNet(hidden_size=64, out_size=32),  # (batch, 64) -> (batch, 32)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc6c17",
   "metadata": {},
   "source": [
    "The first branch takes in the 3D tensor, we apply `MeanAggregator` to get a 2D tensor, and then a `NeuralNet` to get the final output. Check `vectormesh.components.neural` for more models.\n",
    "\n",
    "The second branch doesnt need a aggregator, we already have 2D tensors, so we can directly apply the `NeuralNet`.\n",
    "\n",
    "We want to take the output of the parallel pipeline, and we can do that with `Concatenate2D`, see `vectormesh.components.connectors`. Because we had two (batch, 32) tensors, after concatenation we have (batch,64) vectors, so we apply a final `NeuralNet` to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pipeline(X)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2636224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import ReportTypes, Trainer, TrainerSettings\n",
    "\n",
    "from vectormesh.components.metrics import F1Score\n",
    "from vectormesh.data.vectorizers import detect_device\n",
    "\n",
    "device = detect_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "log_dir = Path(\"demo\").absolute()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[F1Score()],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(trainloader),\n",
    "    valid_steps=len(trainloader),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=pipeline,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainloader,\n",
    "    validdataloader=trainloader,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38941804",
   "metadata": {},
   "source": [
    "And, finally, lets have a look at `vectormesh.components.gating`. I have implemented a few variations of skip/gating, here is a demo of `Skip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import Projection, Skip\n",
    "\n",
    "parallel = Parallel(\n",
    "    [\n",
    "        Serial([MeanAggregator(), NeuralNet(hidden_size=768, out_size=32)]),\n",
    "        # (batch, chunks, dims) -> (batch, dims) -> (batch, 32)\n",
    "        Serial([NeuralNet(hidden_size=123, out_size=32)]),\n",
    "        # (batch, dims) -> (batch, 32)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Serial(\n",
    "    [\n",
    "        parallel,  # (X1, X2) -> (batch, 32), (batch, 32)\n",
    "        Concatenate2D(),  # (batch, 32), (batch, 32) -> (batch, 64)\n",
    "        Projection(in_size=64, out_size=32),  # (batch, 64) -> (batch, 32)\n",
    "        Skip(\n",
    "            transform=NeuralNet(hidden_size=32, out_size=32),\n",
    "            in_size=32,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a608955",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=pipeline,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainloader,\n",
    "    validdataloader=trainloader,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "trainer.loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectormesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from vectormesh.data.cache import VectorCache\n",
    "\n",
    "artefacts = Path(\"../artefacts\")\n",
    "trainpath = next(artefacts.glob(\"*bert*train/\"))\n",
    "validpath = next(artefacts.glob(\"*bert*valid/\"))\n",
    "traincache = VectorCache.load(path=trainpath)\n",
    "validcache = VectorCache.load(path=validpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18e37d",
   "metadata": {},
   "source": [
    "We load the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eab12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincache, validcache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac01546",
   "metadata": {},
   "source": [
    "For this notebook, lets create a subset, 1024 for train, 1024 for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ec7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = traincache.select(range(1024))\n",
    "valid = validcache.select(range(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b210da4",
   "metadata": {},
   "source": [
    "Check how a single item looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada719e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = \"legal_dutch\"  # the vector we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9f9bf",
   "metadata": {},
   "source": [
    "If we iterate a batch, we get a list of tensors, where every tensor has a different chunk size (because the texts have different lengths). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train.iter(batch_size=16):\n",
    "    emb = batch[column_name]\n",
    "    print(\"Checking the shapes of the embeddings in the batch:\")\n",
    "    for e in emb:\n",
    "        print(e.shape)\n",
    "    break\n",
    "print(f\" Note that the type of emb is {type(emb)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ee85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cnt = Counter()\n",
    "for e in train.iter(batch_size=64):\n",
    "    for tensor in e[column_name]:\n",
    "        cnt[tensor.shape[0]] += 1\n",
    "\n",
    "shapes = sorted(cnt.keys())\n",
    "frequencies = [cnt[s] for s in shapes]\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(shapes, frequencies, color=\"skyblue\", edgecolor=\"black\", alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Tensor Shape (Dimension 0)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"Distribution of Tensor Shapes\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4762330",
   "metadata": {},
   "source": [
    "If we want to batch, we need to pad them. Lets use a FixedPadding, such that every tensor has a shape (chunk dim) with every chunk the same size. Note this means we loose data for some documents!\n",
    "\n",
    "(question: which type of model can handle (chunk dim) tensors where every batch has a different chunk size?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a02841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import FixedPadding\n",
    "\n",
    "padder = FixedPadding(max_chunks=30)\n",
    "# change the max_chunks, or use DynamicPadding if your model can handle dynamic sizes\n",
    "\n",
    "i = 0\n",
    "for batch in train.iter(batch_size=16):\n",
    "    emb = padder(batch[column_name])\n",
    "    print(emb.shape)\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4eae3",
   "metadata": {},
   "source": [
    "There are models that handle 3D tensors well. \n",
    "\n",
    "However, we can also aggregate the 3D tensors; see vectormesh.components.aggregation for a few examplea few examples. Lets just use the simplest, a mean aggregation over the chunk dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49501d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import MeanAggregator\n",
    "\n",
    "aggregator = MeanAggregator()\n",
    "padder = FixedPadding(max_chunks=30)\n",
    "for batch in train.iter(batch_size=16):\n",
    "    emb = padder(batch[column_name])\n",
    "    agg = aggregator(emb)\n",
    "    print(agg.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a571530",
   "metadata": {},
   "source": [
    "We can wrap this `MeanAggregator` in a `Serial` pipeline. This will process the components sequentially. \n",
    "Because we have just one component, this is exactly the same as just using the `MeanAggregator` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import Serial\n",
    "\n",
    "pipeline = Serial([MeanAggregator()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = FixedPadding(max_chunks=30)\n",
    "for batch in train.iter(batch_size=16):\n",
    "    emb = padder(batch[column_name])\n",
    "    output = pipeline(emb)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514058d3",
   "metadata": {},
   "source": [
    "But the advantage of `Serial` is that we can easily add more components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8251e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectormesh.components import NeuralNet\n",
    "\n",
    "pipeline = Serial([MeanAggregator(), NeuralNet(hidden_size=768, out_size=32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = FixedPadding(max_chunks=30)\n",
    "for batch in train.iter(batch_size=16):\n",
    "    emb = padder(batch[column_name])\n",
    "    output = pipeline(emb)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d09254",
   "metadata": {},
   "source": [
    "We want to run predictions on this output. Currently, we have a model that does:\n",
    "\n",
    "1. Input: (batch, chunks, dim)\n",
    "2. Aggregation over chunks -> (batch, dim)\n",
    "3. Feed to a Linear layer -> (batch, num_classes)\n",
    "\n",
    "All we need is the label to do supervised machine learning.\n",
    "\n",
    "Lets turn the labels into one-hot encoded vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdedb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class OneHot(BaseModel):\n",
    "    \"\"\"\n",
    "    Turns a sparse integer label into a one-hot encoded vector.\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes: int\n",
    "    label_col: str\n",
    "    target_col: str\n",
    "\n",
    "    def __call__(self, observation):\n",
    "        vec = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        vec[observation[self.label_col]] = 1.0\n",
    "        return {self.target_col: vec}\n",
    "\n",
    "\n",
    "onehot = OneHot(num_classes=32, label_col=\"labels\", target_col=\"onehot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh = train.map(onehot)\n",
    "valid_oh = valid.map(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e6df4",
   "metadata": {},
   "source": [
    "The main issue we now have, is how to batch the dictionarys into padded tensors, such that we can feed them into our pipeline and directly use `mltrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "class Collate(BaseModel):\n",
    "    \"\"\"\n",
    "    processes a batch of Dataset items into padded tensors\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_col: str\n",
    "    target_col: str\n",
    "    padder: Callable\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        embeddings = [item[self.embedding_col] for item in batch]\n",
    "        X = self.padder(embeddings)\n",
    "        y = torch.stack([item[self.target_col] for item in batch]).float()\n",
    "        return X, y\n",
    "\n",
    "\n",
    "collate_fn = Collate(\n",
    "    embedding_col=\"legal_dutch\",\n",
    "    target_col=\"onehot\",\n",
    "    padder=FixedPadding(max_chunks=30),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c6f15",
   "metadata": {},
   "source": [
    "We can now connect the `collate_fn` to the `DataLoader`, and we will get batches tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7022534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train_oh, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "validloader = DataLoader(valid_oh, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5202576",
   "metadata": {},
   "source": [
    "Let us check the shapes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(trainloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b879910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from mltrainer import ReportTypes, TrainerSettings\n",
    "\n",
    "from vectormesh.components.metrics import F1Score\n",
    "\n",
    "log_dir = Path(\"demo\").absolute()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[F1Score()],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(trainloader),\n",
    "    valid_steps=len(validloader),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa8749",
   "metadata": {},
   "source": [
    "We have multilabels, so we use Binary Cross Entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc538e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfb58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import Trainer\n",
    "\n",
    "from vectormesh.data.vectorizers import detect_device\n",
    "\n",
    "device = detect_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=pipeline,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainloader,\n",
    "    validdataloader=validloader,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf88049",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529141e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "shutil.rmtree(Path(\"logs\"), ignore_errors=True)\n",
    "shutil.rmtree(Path(\"tmp\"), ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectormesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
